import streamlit as st
import google.generativeai as genai
import pandas as pd
import warnings
import os  # <--- 住驻 转   转 拽 砖

# --- 1. 专转 驻 专转 ---
warnings.filterwarnings("ignore")

st.set_page_config(page_title=" 转 拽 驻专拽", layout="wide", page_icon="")

# --- 2. 住专 RTL (注专转) ---
st.markdown("""
<style>
    .stApp { direction: rtl; text-align: right; }
    .stChatMessage { text-align: right; direction: rtl; }
    p, h1, h2, h3 { text-align: right; }
</style>
""", unsafe_allow_html=True)


# --- 3. 注转 转 (专住 转拽转 ) ---
@st.cache_data
def load_data():
    data_dict = {}

    # 砖 转 转 砖 转拽 砖 爪 拽抓  (AskUni.py)
    #  驻转专 转 注 砖专  爪 转 拽爪
    current_dir = os.path.dirname(os.path.abspath(__file__))

    # 转 转  拽爪
    path_admission = os.path.join(current_dir, "bgu_admission_complete.csv")
    path_projects = os.path.join(current_dir, "Projects_Classified.csv")

    # 注转 拽抓 拽
    try:
        df_admission = pd.read_csv(path_admission)
        data_dict["admission"] = df_admission
    except Exception:
        data_dict["admission"] = None

    # 注转 拽抓 驻专拽
    try:
        df_projects = pd.read_csv(path_projects)
        data_dict["projects"] = df_projects
    except Exception:
        data_dict["projects"] = None

    return data_dict


# 注转 转 砖转
all_data = load_data()

# 拽 爪转 砖转  拽爪 住专
if all_data["admission"] is None:
    st.error("锔  爪转 爪 转 拽抓: bgu_admission_complete.csv ( 砖 转 转拽 注 拽)")
if all_data["projects"] is None:
    st.error("锔  爪转 爪 转 拽抓: Projects_Classified.csv ( 砖 转 转拽 注 拽)")

# --- 4. 专转  ---
api_key = "YOUR_API_KEY"
genai.configure(api_key="AIzaSyDE1qKjnw4qpjALtD7713rM0hq1w8P02HE")
model = genai.GenerativeModel('gemini-2.5-flash')

# --- 5. 砖拽 砖转砖 ---
st.title("  注: 拽 驻专拽")
st.write("砖 转 注 转 拽  注 驻专拽 住.")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- 6. 拽  ---
if prompt := st.chat_input("拽 转 砖 砖 ..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    try:
        with st.chat_message("assistant"):
            with st.spinner('驻砖 转...'):

                # 转 注 
                context_str = ""

                if all_data["admission"] is not None:
                    context_str += f"\n--- 转 转 拽 (Admission) ---\n{all_data['admission'].to_string()}\n"

                if all_data["projects"] is not None:
                    context_str += f"\n--- 转 驻专拽 (Projects) ---\n{all_data['projects'].to_string()}\n"

                if context_str == "":
                    context_str = " 转  专注."

                # 转  
                full_prompt = (
                    f"转 注专 . 砖  砖 砖转 转 转 砖转 (驻注转 ).\n"
                    f"1. 转 转 拽.\n"
                    f"2. 转 驻专拽.\n"
                    f"注 注 砖转 砖转砖  专拽 注 住 注 转 .\n"
                    f" 注  驻注 祝 转 转, 爪 转 驻专砖.\n\n"
                    f"注 转:\n{context_str}\n\n"
                    f"砖: {prompt}"
                )

                # 砖 
                response = model.generate_content(full_prompt)
                st.markdown(response.text)

        st.session_state.messages.append({"role": "assistant", "content": response.text})

    except Exception as e:
        st.error(f"砖 拽转 转砖: {e}")